{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Psyched: A Closer Look Into Reproducibility In Psychological Research\n",
    "\n",
    "## Full Text Mining Script: Part 1 - Metadata + P-values\n",
    "This script is set up for ProQuest TDM Studio's corpus of Psychology texts.\n",
    "\n",
    "Author: Yuyang Zhong (2020). This work is licensed under a [Creative Commons BY-NC-SA 4.0 International\n",
    "License][cc-by].\n",
    "\n",
    "![CC BY-NC-SA 4.0][cc-by-shield]\n",
    "\n",
    "[cc-by]: http://creativecommons.org/licenses/by/4.0/\n",
    "[cc-by-shield]: https://img.shields.io/badge/license-CC--BY--NC--SA%204.0-blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = \"../articles/samples/\"\n",
    "out_path = \"../data/samples/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1554207703.txt', '1011297999.txt', '1509629602.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(in_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture(in_path, out_path, out_name):\n",
    "    \"\"\"\n",
    "    An encapsulating function to scrape metadata, research statistics,\n",
    "    and reproducibility practices.\n",
    "    \n",
    "    @parameter in_path: the path of the input files\n",
    "    @parameter out_path: the path to output file\n",
    "    @parameter out_name: name for output file\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Make sure our parameters are strings\n",
    "    assert(type(in_path) == str)\n",
    "    assert(type(out_path) == str)\n",
    "    assert(type(out_name) == str)\n",
    "    \n",
    "    # Loop through the in_path directory for files\n",
    "    data={}\n",
    "    for f in os.listdir(in_path):\n",
    "               \n",
    "        ##### Set up XML parser & JSON output file #####\n",
    "        data[f] = {}\n",
    "        root = ET.parse(in_path+f).getroot()\n",
    "        \n",
    "        \n",
    "        ##### Capture Metadata #####\n",
    "        ## Title\n",
    "        data[f]['Title'] = root.find('Obj').find('TitleAtt').find('Title').text\n",
    "        \n",
    "        ## Date Published\n",
    "        data[f]['Date Published'] = root.find('Obj').find('NumericDate').text\n",
    "        \n",
    "        ## Peer Reviewed\n",
    "        pr = root.find('Obj').find('PeerReviewed').text\n",
    "        'Yes' if pr == 'true' else 'No'\n",
    "        data[f]['Peer Review'] = pr\n",
    "        \n",
    "        ## DOI\n",
    "        doi = ''\n",
    "        for i in root.find('Obj').find('ObjectIDs').iter('ObjectID'):\n",
    "            curr = i.find('DOI')\n",
    "            if curr != None:\n",
    "                doi = curr.text\n",
    "        data[f]['DOI'] = doi\n",
    "        \n",
    "        ## Author List\n",
    "        authors=[]\n",
    "        for i in root.find('Obj').find('Contributors').iter('Contributor'):\n",
    "            author = i.find('Author')\n",
    "            if author != None:\n",
    "                authors.append(author.find('NormalizedDisplayForm').text)\n",
    "        data[f]['Author'] = authors\n",
    "        \n",
    "        ## Keywords & Identifiers\n",
    "        identifiers=[]\n",
    "        for i in root.find('Obj').find('Terms').iter('FlexTerm'):\n",
    "            iden = i.find('Identifiers')\n",
    "            if iden != None:\n",
    "                identifiers.append(iden.text)        \n",
    "        data[f]['Keywords'] = identifiers\n",
    "        \n",
    "        ## Methodology\n",
    "        methodology=[]\n",
    "        for i in root.find('Obj').find('Terms').iter('FlexTerm'):\n",
    "            method = i.find('Methodology')\n",
    "            if method != None:\n",
    "                methodology.append(method.text)        \n",
    "        data[f]['Methodology'] = methodology\n",
    "        \n",
    "        ## Number of References\n",
    "        try: \n",
    "            data[f]['References'] = root.find('Obj').find('DocFeatures').find('NumRefsAtt').find('NumRefs').text\n",
    "        except AttributeError:\n",
    "            data[f]['References'] = ''\n",
    "        \n",
    "        ## Journal\n",
    "        data[f]['Journal'] = root.find('PublicationInfo').find('PublicationTitleAtt'\n",
    "                                                                   ).find('PublicationTitle').text\n",
    "        \n",
    "        ## Volume\n",
    "        try:\n",
    "            data[f]['Volume'] = root.find('PublicationInfo').find('Volume').text\n",
    "        except AttributeError:\n",
    "            data[f]['Volume'] = ''\n",
    "        \n",
    "        ## Issue\n",
    "        try:\n",
    "            data[f]['Issue'] = root.find('PublicationInfo').find('Issue').text\n",
    "        except AttributeError:\n",
    "            data[f]['Issue'] = ''\n",
    "        \n",
    "        ## Pages\n",
    "        try:\n",
    "            data[f]['Pages'] = root.find('Obj').find('PrintLocation').find('Pagination').text\n",
    "        except AttributeError:\n",
    "            data[f]['Pages'] = ''\n",
    "        \n",
    "        \n",
    "        ##### Capture P-Values #####\n",
    "        try:\n",
    "            raw_text = root.find('TextInfo').find('PreformattedData').find('PsycArticles').text\n",
    "        except AttributeError:\n",
    "            raw_text = ''\n",
    "        \n",
    "        ## strip HTML tags\n",
    "        raw_text = re.sub(r'<[^>]*>', '', raw_text)\n",
    "        \n",
    "        ## remove nextline character\n",
    "        raw_text = re.sub(r'\\n\\s*', '   ', raw_text)\n",
    "        \n",
    "        ## Replace HTML named symbols \n",
    "        html_symbols = {\n",
    "            \"&\": r'&amp;',\n",
    "            '\"': r'&quot;',\n",
    "            \"'\": r'&apos;',\n",
    "            \">\": r'&gt;',\n",
    "            \"<\": r'&lt;',\n",
    "        }\n",
    "        for i in iter(html_symbols):\n",
    "            raw_text = re.sub(html_symbols[i], i, raw_text)\n",
    "        \n",
    "        data[f]['P-Values'] = re.findall(r'p\\s*([\\<|\\>|\\=]\\s*\\d?\\.\\d+)', raw_text)\n",
    "#         data[f]['Inequalities'] = re.findall(r'p\\s*([\\<|\\>|\\=])\\s*\\d*\\.\\d+', raw_text)\n",
    "        \n",
    "        \n",
    "    ##### Write Output #####\n",
    "    with open(out_name + '.json', 'w') as outfile:\n",
    "        json.dump(data, outfile, indent=2)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture(in_path, out_path, 'samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
