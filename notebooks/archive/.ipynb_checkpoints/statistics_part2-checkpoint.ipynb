{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Psyched: A Closer Look Into Reproducibility In Psychological Research\n",
    "\n",
    "## Statistics Mining Script: Part 2 - Test Statistics \n",
    "This script is set up for ProQuest TDM Studio's corpus of Psychology texts.\n",
    "\n",
    "Author: Yuyang Zhong (2020). This work is licensed under a [Creative Commons BY-NC-SA 4.0 International\n",
    "License][cc-by].\n",
    "\n",
    "![CC BY-NC-SA 4.0][cc-by-shield]\n",
    "\n",
    "[cc-by]: http://creativecommons.org/licenses/by/4.0/\n",
    "[cc-by-shield]: https://img.shields.io/badge/license-CC--BY--NC--SA%204.0-blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Up & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File Path & File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../articles/samples/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"1011297999.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = ET.parse(path+file).getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning up full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = root.find('TextInfo').find('PreformattedData').find('PsycArticles').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strip HTML tags & next line characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = re.sub(r'<[^>]*>', '', raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = re.sub(r'\\n\\s*', '   ', raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_symbols = {\n",
    "    \"&\": r'&amp;',\n",
    "    '\"': r'&quot;',\n",
    "    \"'\": r'&apos;',\n",
    "    \">\": r'&gt;',\n",
    "    \"<\": r'&lt;',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in iter(html_symbols):\n",
    "    raw_text = re.sub(html_symbols[i], i, raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"   Journal of Personality and Social Psychology   Attitudes and Social Cognition   0022-3514   1939-1315   American Psychological Association   psp_103_1_38   10.1037/a0028124   2012-10021-001   Why and When Peer Prediction Is Superior to Self-Prediction: The Weight Given to Future Aspiration Versus Past Achievement   Eliot R.   Smith   Editor   Erik G.   Helzer   David   Dunning   Department of Psychology, Cornell University   This research was supported financially by National Science Foundation Grant 0745806, awarded to David Dunning. We thank members of the Dunning Self and Social Insight Lab for their comments. We also thank Jack Cao, Dan Connolly, Polina Minkin, Mary Panos, and Carolyn Spiro for their assistance with data collection.   Erik G. Helzer, Department of Psychology, Cornell University, Ithaca, NY 14853-7601   egh42@cornell.edu   April   16, 2012   July   2012   103   1   38   53   September   7, 2011   February   21, 2012   February   27, 2012   2012   American Psychological Association   Peer predictions of future behavior and achievement are often more accurate than those furnished by the self. Although both self- and peer predictions correlate equally with future outcomes, peers tend to avoid the degree of overoptimism so often seen in self-predictions. In 3 studies, the authors tested whether this differential accuracy arises because people give more weight to past behavior when predicting others, but emphasize agentic information, in particular data about their aspiration level, when predicting the self. Studies 1 and 3 showed that the exact same participants rated past behavior more diagnostic of future performance when predicting another person but viewed aspiration-level data as more valuable when someone else was trying to predict them. In Studies 2 and 3 (predicting an upcoming exam score and performance in a lab task, respectively), participants gave greater weight in self-predictions to aspiration-level data than did a yoked peer, who instead gave greater weight to evidence of past achievement. This differential weighting explained why peer predictions tended to be less optimistic and, thus, more accurate. Discussion centers on strategies for predicting future behavior and why people may remain ignorant of their own incompetence despite feedback.   self-prediction   social prediction   optimism   self-enhancement   accuracy   To know others is wisdom, to know one's self is enlightenment.   —Lao Tzu, Philosopher   The choices people make today are very often based on their expectations of success tomorrow. The decision to forgo the gym on a busy day is in part determined by one's prediction that one will make it up in the near future. Insuring one's house (or one's self) is a choice made with an eye toward tomorrow's risks. And, whether to propose to one's beloved is based on one's assessment of the future prospects of the relationship along many tomorrows. In important ways, leading a successful and satisfying life often entails accurately anticipating one's future.   With this in mind, the psychological literature on self-prediction presents a cautionary tale. When it comes to consequential events, self-predictions of future achievements and outcomes are fraught with error and bias (Dunning, 2005; Dunning, Heath, & Suls, 2004; Weinstein, 1980; Wilson & Gilbert, 2003). People, for example, overestimate the chance they will engage in personally desirable acts such as voting and donating to charity (Balcetis & Dunning, 2008, in press; Balcetis, Dunning, & Miller, 2008; Epley & Dunning, 2000, 2006), as well as the speed with which they will complete complex projects (Buehler, Griffin, & MacDonald, 1997; Buehler, Griffin, & Ross, 1994).   These mistakes are curious, in that predictions of peer behavior tend to be more insightful. Although people overestimate how frequently they will perform desirable acts, they are roughly accurate in predicting the likelihood that their peers will behave in socially desirable ways (Balcetis & Dunning, 2008, in press; Balcetis et al., 2008; Epley & Dunning, 2000, 2006). When predicting who will receive early promotion to Naval officership, predictions by peers do a much better job identifying who will be promoted than do self-predictions (Bass & Yammarino, 1991). Roommates and parents are better able to predict the longevity of a college student's romance than the student enmeshed in it can (MacDonald & Ross, 1999). The same holds true for surgical residents: Their self-ratings of surgical skill fail to predict their performance on the formal board exam they must take at the end of their surgical rotation, yet the predictions of their peers and supervisors strongly predict such performance (Risucci, Tortolani, & Ward, 1989).   In sum, the psychological literature suggests, in the words of the quote that begins this article, that people show more wisdom than they do enlightenment in their predictions. The wisdom they demonstrate in understanding their peers' behavior seems not to translate into enlightened forecasts about themselves. Why is this so?   The Accuracy of Self- and Peer Prediction Compared   To answer the question of why and when peer forecasts are superior to those provided by the self, one must first specify exactly how peer forecasts are superior. One must look specifically at two different measures of accuracy. The first measure is the traditional correlation coefficient, which assesses the strength of the relationship between what people predict and their ultimate behavior. Here, it appears that self and peers are similarly accurate (Vazire & Mehl, 2008). There are occasions in which the predictions of peers, such as friends, classmates, and roommates, are more closely correlated with future behavior than are self-predictions (Bass & Yammarino, 1991; Dunning et al., 2004; Kolar, Funder, & Colvin, 1996; MacDonald & Ross, 1999; Risucci et al., 1989), but there are also situations in which self-predictions prove superior (Shrauger & Osberg, 1981), particularly when the behavior is a private or an internal one (Spain, Eaton, & Funder, 2000; Vazire, 2010; Vazire & Mehl, 2008).   The second measure of prediction accuracy relates to the amount of optimism (or bias) expressed in the prediction. It is on this measure that self- and peer predictions most reliably diverge. On the one hand, people tend to offer self-predictions that prove overly optimistic when compared against reality (Dunning et al., 2004; Weinstein, 1980). Peer predictions, on the other hand, tend to avoid this overoptimism in whole or at least in part.   As one example, Epley and Dunning (2006) asked participants in a large lecture class to predict how likely they were, and how likely their peers were, to vote in an upcoming presidential election. After the election, the researchers compared these predictions with the actual number of students who voted. When accuracy was measured as a correlation between predicted and actual behavior, both self- and peer predictions fared equally well. However, when accuracy was measured as an overall difference between predicted and actual behavior, people showed greater wisdom than enlightenment. Although 89% of students predicted that they would vote, only 63.5% did. However, participants predicted that 66.5% of their peers would vote, a figure not differing significantly from the observed rate of behavior. This difference in optimism is not an isolated case (Balcetis & Dunning, 2008, in press; Balcetis et al., 2008; Epley & Dunning, 2000, 2006; MacDonald & Ross, 1999).   Aims of the Present Research   In the present article, we placed self- and peer predictions under close scrutiny to see whether we can explain why peer predictions tend to exhibit significantly more accuracy, particularly when it comes to optimistic bias, than self-predictions do. We asked how people might approach self- and peer predictions differently and whether any divergence in approach may lead to differences in optimism and accuracy.   To foreshadow our story somewhat, we propose that people are prone to an agency bias, giving greater weight to agentic aspects of their character in self-prediction than they do in predictions involving other people. People think of themselves as planners who act on the environment to achieve goals they articulate for themselves. To be sure, they are aware that other people have goals, form intentions, and think of themselves as independent agents who shape their environments. They just do not give these aspects of another person's character as much weight as they do for the self. Instead, for others, they give heavier weight to the person's past behavior. Because the past is so often an accurate prologue to the present, peer predictions, thus, prove more accurate.   In its specifics, in the present article, we compare how much weight people give to two particular pieces of data, past behavior and aspirations for future behavior, when making self- and peer predictions. We anticipated that people in their self-predictions would give too much weight to their level of aspiration and too little weight to past behavior. In peer prediction, people would give lesser and more appropriate weight to aspirations, and greater and appropriate weight to the past.   Note that implicit in these predictions is a normative statement about the amount of weight one ought to give to these pieces of information if one wants to arrive at an accurate future forecast. Thus, we not only explore in the present article whether self-predictions weight information differently than peer predictions but also take the novel step of comparing information weighting by self and peer with the actual predictive power of these behavioral indicators, to provide a first exploration into whether the different weight given to future aspiration versus past achievement explains the differential accuracy of peer versus self-prediction.   Why Past Behavior Matters   There are many reasons to use past behavior as an indicator of future action and achievement. The overarching reason is that past behavior is a product of a number of causal variables that sum up to produce it—and that suite of causal variables in the same proportion is likely to be in play for any future behavior in a similar context (for a similar argument, see Hall, Ariss, & Todorov, 2007; Ouellette & Wood, 1998). As long as one assumes that all of these potentially causal variables still apply the next time a person attempts the same behavior, past performance can serve as a succinct summary of how the same variables are likely to affect the future (Diener & Larsen, 1984; Mehl & Pennebaker, 2003; Nezlek, 1993).   It appears that people have an intuitive understanding of this fact. A handful of studies have documented people's willingness to lean on past behavior as a way of understanding the current or future behavior of their peers. Epley and Dunning (2000) showed that people use population base rates when predicting the likelihood that an individuated peer would act in a prosocial or generous manner (see also Balcetis, 2009; Epley & Dunning, 2006). Buehler et al. (1994) have shown that, in the domain of planning, participants cite a person's previous history more often than that person does when assessing how quickly that person will complete a project. Finally, when peers judge the amount of conformity in a target's judgments, they tend to use that person's behavior to inform their estimates; targets themselves, however, turn a blind eye to such information (Pronin, Berger, & Molouki, 2007; Pronin & Kugler, 2007).   How Self-Prediction May Be Different   In predicting themselves, however, people abandon the wisdom gleaned from observation of past behavior and instead emphasize their agentic qualities, those allowing them to be proactive and self-regulating beings actively working to achieve desired outcomes. They emphasize the strength of their intentions (Koehler & Poon, 2006; Koehler, White, & John, 2011; Kruger & Gilovich, 2004), reasons for action (Malle, 2005), introspections (Andersen & Ross, 1984; Pronin, 2008), best-laid plans (Buehler et al., 1994; Newby-Clark, Ross, Buehler, Koehler, & Griffin, 2000), and goals (Peetz & Buehler, 2009). People perceive their behavior as less governed by personal dispositions (Baxter & Goldberg, 1987). They also construe their own behavior as freer of constraints, more unpredictable, and more a function of their desires and intentions than is the behavior of others (Pronin & Kugler, 2010). This suite of beliefs may make people particularly prone to illusions of control (Langer, 1975) over outcomes that are essentially random in nature. Thus, whereas other people's behavior seems to arise from a steady state of causal factors both within and outside the person, people interpret their own behavior more as imposing their will upon the environment, shaping it and their behavior to achieve the aspirations they have set for themselves.   This difference in emphasis may be due to the fact that people often experience their own goals, desires, and intentions (but not those of others) as real psychological phenomena that precede the very behavior initiated to achieve these ends (Aarts, Custers, & Marien, 2009; Wegner, 2002). Thus, these states are forefront in people's causal models of themselves more than in their understanding of others. In addition, people situate their representations of self more in what they strive to be rather than in who they have already been. Williams and Gilovich (2008) have shown that people represent themselves more in terms of the future—of whom they will become—than they do other people, seeing themselves as ever-changing entities defined more by hopes and dreams than by the past. People also represent themselves more in terms of what they intend (Kruger & Gilovich, 2004) and in their potential, whereas they represent others more in terms of typical or average behavior (Williams, Gilovich, & Dunning, 2012).   Overview of the Present Studies   Can differences in predictive accuracy be tied directly to the trade-offs people make in the use of agentic and behavioral information when thinking about self and other? To date, we know of no comprehensive exploration of this issue. There are partial and indirect hints that people give too much weight to agentic information in self-prediction. To the extent that people strongly intend to perform a behavior, such as giving blood, they overpredict that they will do it (Koehler & Poon, 2006). To the degree that saving money is desirable, people underpredict how much they will spend in the next month (Peetz & Buehler, 2009). Conversely, to the extent that people pay attention to stable aspects of their own personality and behavior, they are more accurate in their predictions (Osberg & Shrauger, 1986). However, the predictive value of past behavior has not been directly compared with the diagnostic value of agentic aspects of self. In addition, what peers do when asked to make similar predictions has not been placed under scrutiny. Would they give less and more appropriate weight to agentic information—and thus achieve greater accuracy?   In the three studies reported here, we directly tested whether the superior accuracy achieved by peers over the self in prediction was linked to differential weight each gave to achievement in the past versus aspiration for the future. In Studies 1 and 3, we examined whether people, even when confronting incentives to be accurate, displayed a comparative preference for aspiration-level data over information about past performance when it was the self rather than a peer who was being predicted.   In Studies 2 and 3, we asked participants to make self- and peer predictions and examined how much weight they actually gave to aspiration level versus past performance. In Study 2, we asked students about their aspiration level (i.e., the target score they were shooting for) regarding an upcoming classroom exam as well as their past performance on a previous test in that same class, and then asked them to predict how they would perform on that upcoming exam. We yoked each self-predictor with a peer, gave that peer the exact same information, and asked for his or her prediction about the student's upcoming performance. In Study 3, we created a lab analogue in which people were given experience in a competitive task, and were then asked to predict the performance of themselves and a series of yoked peers in the next round.   We anticipated, given past research, that peer predictions would prove more accurate. Self- and peer predictions would be equally correlated with actual performance, but peer predictions would more successfully avoid the overoptimism seen in self-predictions. This difference would be explained by trade-offs in the weight given to aspiration level versus past behavior. Whereas self-predictions would weight aspiration information over past achievement, peer predictions would weight past achievement over information about aspiration.   1   Study 1   Study 1 was designed as an initial test of whether people assign different values to aspiration level and past behavior in self- versus peer prediction. Participants took part in a two-stage prediction exercise. In one stage, the participant predicted a peer's performance on an upcoming exam (i.e., you, the participant will predict a peer's performance). In the other stage, the participant's exam performance was predicted by a peer (i.e., another person will predict your performance). Both predictions offered prize money for accuracy. Critically, in this exercise, participants had to make choices about the information they wanted in order to make an accurate peer prediction, as well as choices about the information they wanted to give to their peers who were predicting them.   Within the pieces of information people could consider were data about aspiration level (i.e., the test-taker's target score) and past performance (i.e., score on a previous exam in the same class). We predicted that the information participants wanted when making a peer prediction would differ from the information they gave to a peer who was making a prediction about them. Participants would want information about a peer's past behavior, but would find that same information less informative to a peer who was predicting them. In contrast, participants would give information about their aspiration level to a peer predicting them, but would be less likely to want that same information if they were trying to predict a peer.   Method   Participants   Forty-two undergraduates participated in exchange for extra credit in their psychology courses at Cornell University. The study was run during the 4-week period between Exam 1 and Exam 2 in selected sophomore- and junior-level psychology courses. Each participant was yoked to the participant run prior to them, resulting in 41 sets of paired data.   Materials and procedure   Participants were run one at a time. They were informed they were participating in a study about how people make predictions about the future, and would be making some predictions about themselves and about another participant in the study. The experimenter then walked them through the three phases of the study.   Phase 1: Self-reported exam information   Participants began by filling out an information packet about their next exam in the course for which they were receiving extra credit. They provided information about a number of variables relevant to their future performance, including their score on the first exam and their target score for the second exam (see Table 1 for items). Embedded in the questions was also a place for participants to make their own prediction about how well they would perform on the second exam (with a score from 0% to 100%). Once participants had finished the packet, the experimenter walked them through either Phase 2 or Phase 3, which was counterbalanced across participants.   Phase 2: Giving information to others   In an “information giving” task, each participant was informed that a peer would be predicting the participant's performance on the next exam, and that if their peer offered an accurate prediction (within 2.5 points of their actual score), the peer and the participant would be awarded up to $5. The experimenter told participants, however, that not all of the information provided on the self-report measure would be made available to their yoked peer. Instead, their peer would receive only a subset of five pieces of information. Participants then selected which five pieces of information they wanted made available to their yoked peer.   Participants were informed that the five pieces of information they had just selected would be made available one at a time. The first piece of information would be given to their yoked peer for free. After that, each piece of information would come at a cost of $1 deducted from any potential earnings from an accurate prediction. Participants were informed that after each piece of information, the yoked peer (who also knew they were being charged for the information) would decide whether they were ready to make the prediction or whether they would like to purchase an additional piece of information. Participants were explicitly told that their goal was to lead their peer to the “greatest amount of accuracy using the least amount of information.” Participants then rank ordered the information from the first, most valuable piece to the fifth, least valuable piece.   Phase 3: Wanting information from others   This “information wanting” task closely mimicked the information giving one, but placed participants on the other side of the prediction. They were informed that they would be making a prediction about a different yoked peer (i.e., not the same peer who would be predicting them) on the basis of five pieces of information. After selecting the five pieces of information that were most valuable, the experimenter then explained that the pieces of information would be made available one at a time. The pay-off structure for an accurate prediction was the same as in the information giving task (i.e., the first piece of information was free; each successive piece cost $1). Participants again were reminded to order the information so that they could make the best prediction with the least amount of information. They ranked the information from 1 to 5 on a separate sheet of paper.   Participants were then given the first piece of information they requested and were offered the opportunity to make their prediction on the basis of that one piece of information or buy an additional piece of information for $1. This continued until they felt ready to make a prediction, which they indicated on a separate sheet of paper.   After these tasks, participants were debriefed as to the purpose of the experiment. They were informed that they would, in fact, be rewarded if their prediction of the peer's performance proved accurate. They were also informed that they would be rewarded if their own performance was predicted accurately by the yoked peer.   For this experiment, accuracy data were collected in a semiprivate manner so that participants' actual scores were never revealed. Teaching assistants from participants' classes were sent spreadsheets that contained the Student ID of the participant and the prediction of his or her Exam 2 score, as made by the peer. The assistants simply indicated whether that prediction fell inside the 2.5-point range of that constituted an “accurate” prediction. For the purposes of this study, we were interested in potential discrepancies between the information people thought would be diagnostic of their own future performance and the information they thought would be diagnostic of a peer's future performance. Accordingly, we do not provide accuracy data in this study, but return to the question of accuracy in Studies 2 and 3.   Results and Discussion   As a preliminary analysis, we examined how much weight participants gave to their target score versus past performance in self-predictions. Self-predictions of future exam performance were submitted to a multiple regression analysis that included both target and past exam scores. Participants' predictions reflected far more their target score (β = .82, p < .0001) than their past performance (β = .07, p = .15). A comparable analysis was not possible among peer predictions, because peers were not given complete information about target score and past performance before making predictions.   Participants also valued target score for self-prediction more than they did for peer prediction. The proportion who gave their own target score (78%) to their yoked peer, so their peer could predict them accurately, was significantly higher than the number of people who asked for their peer's target score (62%) to aid in predicting that peer (p = .01) by sign test. In contrast, participants valued past performance less for self-prediction than for peer prediction. They were less likely to offer their past exam score to their peer (78%) than they were to ask for that score (92%) to help them predict that peer (p = .03) by sign test.   Preference rankings given to target and past scores mimicked this pattern. Although people showed an overall preference for information about past performance over aspiration level, F(1, 40) = 7.90, p < .01, this preference was moderated by whether the information was relevant to predicting the self or a peer, F(1, 40) = 8.85, p < .01. Participants tended to rank past performance as the first or second most important piece of information for predicting their peer (M = 1.88, SD = 1.47), but ranked past performance as only the second or third most important piece of information for their peer to predict them (M = 2.66, SD = 2.03), t(40) = 2.68, p = .01, d = .43. Target scores were ranked more important for predictions about the self (M = 3.22, SD = 1.95) than for predictions about peers (M = 3.71, SD = 2.01), t(40) = 2.32, p = .02, d = .36.   2   In sum, Study 1 demonstrated that people thought that their level of aspiration was comparatively more diagnostic of their future performance than it was for their peers; they also indicated the opposite for past behavior. Intriguingly, we found this pattern within subjects. Although participants were aware of the inconsistency in their use of information, they nonetheless ranked their target scores as more valuable for self-prediction than for peer prediction and past achievement as more diagnostic for predicting peers than for the self. They did all this even when given direct financial incentives to be accurate.   Study 2   Study 2 was designed to explore whether, when given access to full information, people would show the same tendency for differential weighting of aspiration level versus past behavior in predictions of a real-life performance. Participants gave relevant target score and past performance information and then predicted how well they would do in an upcoming classroom exam. A yoked peer was given the same information and made the same prediction. We predicted that the information trade-offs for self- and peer prediction captured prospectively in Study 1 would play out in the actual predictions people made for themselves and for their peers in Study 2. Self-predictions would give greater weight to target score than would peer predictions. Peer predictions, in contrast, would give greater weight to past performance.   We took pains to assess how these patterns of prediction related to accuracy. Following past work, we predicted that self- and peer predictions would show the same degree of correlation to actual performance but that self-predictions would prove too optimistic relative to peer predictions. We then traced this difference in optimism to the amount of weight given to target score and past performance. We predicted that the weight given in self-prediction to target score would exceed the true relationship of target score to actual performance, and the weight given to past performance would fall short of the actual relationship between past performance and future performance. This would open up “gaps,” or areas in which self-predictions would far exceed actual performance (i.e., when target scores were high, or when past performance was low). Peer predictions, however, would give more appropriate weight to target score and past performance and, thus, not show similar gaps between predicted and actual performance.   Method   Participants   Data from this study were conducted in two waves: one during fall semester and the other during spring semester (note that all yoking happened within semester; thus, self-predictions made in fall [spring] were yoked to peer predictions that were also made in fall [spring]). In the self-prediction condition, 131 participants in two midlevel large-lecture psychology classes completed the self-report information packet used in Study 1. For their participation, they were awarded extra credit in their course. In the peer prediction condition, 103 participants in two different midlevel large-lecture psychology classes took part in exchange for extra credit. This resulted in 103 sets of yoked pairs. Data collection occurred between the time that scores from Exam 1 were distributed and the time that Exam 2 occurred. On average, this amounted to a date that fell 2 or 3 weeks prior to the upcoming exam.   Materials and procedure   Self-prediction   Participants in the self-prediction condition were invited to stay after class for a study about how people make predictions. Students electing to stay were informed that they would be providing information relevant to their Exam 2 performances in the class. After providing informed consent, participants were given the self-report exam information packet from Study 1 (and detailed in Table 1), including a place for them to report their target score for the exam, their performance on Exam 1, and a prediction about their performance on the upcoming exam. Participants were told to take as long as they needed to complete the packet. At the end of the packet, participants were asked whether the experimenters could obtain their actual scores on Exam 2. Participants were also asked whether they consented to having their prediction questionnaire information passed on to another participant, provided all identifying information was removed. We removed participants from the data set if they did not consent to both questions, although consent to both was quite high (88%).   Peer prediction   Participants in the peer prediction condition were instructed that they would be making a prediction about the upcoming exam performance of an actual psychology student from another class (the class and date of the exam were purposely left vague, although peer predictors could get a sense of the student's perceived mastery of the information from the information packet). We then administered to peer predictors one of the questionnaires filled out by a participant in the self-prediction condition. The packets were identical, except that the Student ID number was removed, as were self-predictions for Exam 2 and their answers to the two consent questions at the end of the packets. Yoking was performed randomly. Peer predictors studied the packets for as much time as they liked, and then offered their predictions on a separate sheet of paper.   Actual performance   When data collection was complete and Exam 2 grades had been calculated, the experimenters contacted teaching assistants from both classes to obtain the actual scores for participating students.   Results and Discussion   Accuracy of self- versus peer predictions   To compare the accuracy of self- and peer predictions, we used two distinct analytic strategies. The first assessed how much self- and peer predictions correlated with actual performance and revealed that peer predictions, r(96) = .41, p < .0001, were just as tightly related to actual performance as self-predictions proved to be, r(96) = .40, p < .0001. The second analysis examined the degree to which self- and peer predictions displayed optimistic bias. This analysis showed that both groups, relative to actual performance (M = 80.55, SD = 10.60), were too optimistic, ts(97) = 5.37 and 3.94, ps < .0001, ds = .57 and .42, for self- and peer prediction, respectively. Crucially, though, self-predictions (M = 86.17, SD = 6.73) proved significantly more optimistic than peer predictions (M = 84.61, SD = 6.75), t(102) = 2.66, p < .01, d = .27.   Weight given to past performance versus target score   Why did self-predictions prove more overly optimistic than those furnished by peers? To address this question, we examined whether self- and peer predictions differed in the weight they gave to target score and past performance. We conducted two separate analyses regressing self- and peer predictions, respectively, on target and past scores. Then, to assess the true relationship between target score and past performance to the future, in a third analysis we regressed actual Exam 2 performance on target score and past performance. This final analysis provided the amount of weight one ought to give to past and target scores if one wants to predict with greatest accuracy. The resulting beta weights from all three analyses reflect the independent contribution of target score and past score (controlling for the other variable).   These analyses revealed, as seen in Table 2, that self-predictors gave much weight to their own target scores (β = .68, p < .0001) and relatively little weight to their past performance (β = .21, p < .01). These weights were inappropriate, in that the actual relationship between target score and actual performance was much more shallow—and, indeed, nonsignificant (β = .17, p = .11)—whereas the relationship between past score and actual performance was steeper than that seen in self-prediction (β = .40, p = .001).   To confirm that self-predictions significantly misweighed both target score and past performance, we computed an index of overoptimism (self-predicted minus actual performance on Exam 2) and regressed it on target score and past performance. If participants were giving appropriate weight to both variables, then target score and past performance should fail to correlate with the level of overoptimism that participants displayed. However, to the extent that participants misweighed these two predictor variables, overoptimism should correlate with either or both. Indeed, as predicted, self-predictions misweighed these two variables. Overoptimism was positively related to the target score that participants set (β = .28, p < .02) and negatively related to the past performance they achieved on Exam 1 (β = −.28, p < .02). More specifically, as seen in Figure 1, participants displayed the most overoptimism when they set high target scores or when they performed poorly on Exam 1. These patterns are consistent with the notion that participants were giving too much credence to high levels of aspiration while improperly discounting how diagnostic their past behavior was of future achievement, particularly when that past behavior was lackluster.   3   In contrast, peers avoided this misweighting of target score and past achievement. As also seen in Table 2, the weights peers gave to target score and past achievement (βs = .27 and .62, respectively, ps < .001) were much closer to the observed relationship between these variables and actual performance. Indeed, the degree to which peers displayed overoptimism (i.e., predicted minus actual performance on Exam 2) failed to correlate with target score or past performance (both βs = .00), confirming that peers gave much more appropriate weight to these two variables in their predictions.   In a final analysis, we explored whether differential weighting of target score and past performance explained the divergence between self- and peer prediction. We computed a comparative optimism index (self-prediction minus peer prediction) and asked whether this difference could be explained by an overemphasis on target score and a concomitant underemphasis on past performance. Comparative optimism was related to the target score participants had set for themselves (β = .45, p < .0001) and negatively related to their past performance (β = −.47, p < .0001; see Table 2). As seen in Figure 1, the relationship between peer prediction and target score was much more shallow than it was for self-prediction. Peers also gave greater weight to low past performance relative to self-prediction. This meant that peers were more pessimistic in their predictions, relative to the self, to the extent that the self's levels of aspiration was high and when previous performance proved to be low.   Summary   In a comparison of the accuracy of self- versus peer prediction, self- and peer predictions proved to be equally correlated with future performance, but peer prediction avoided, at least in part, the overoptimism pervasive in self-predictions. This difference in prediction accuracy was tied to the weight given to aspiration level (i.e., target performance) versus past behavior (e.g., achievement in a previous exam). Peer predictions gave weight to target and past performance that almost exactly mimicked the actual relationship found between these two variables and the actual score that participants obtained in the subsequent exam. In contrast, self-predictions weighed target and past performance more imperfectly— overweighing target information and underweighing past performance relative to their true relationship to actual performance. This misweighing served as an explanation for why self and peers differed in the level of overoptimism they displayed in their predictions. Participants showed more optimism relative both to reality and to their yoked peers when they either set high target scores or had posted low actual achievement in the past.   4   Study 3   Study 3 was a laboratory study designed with several aims in mind. We presented participants with a number of prediction tasks comprising conceptual replications of both Studies 1 and 2 and extended the results from those studies in two ways. First, in Study 3 we examined whether the use of aspiration level rather than past performance prompted more overly optimistic predictions. We accomplished this by exploring whether peer predictions made on the basis of participants' aspirations were more overly optimistic than peer predictions made on the basis of past behavior. Second, in Study 3 we went beyond the correlational nature of Study 2 to experimentally manipulate aspiration level and performance. In doing so, we could confirm that these two variables played a causal role in shaping the self-prediction participants offered and the optimism often seen in them.   All participants in the study completed a timed cup-stacking task. In the portion of the study that replicated Study 1, they were given chances to win cash by making different types of predictions before completing a second round of the task. Participants completed three prediction tasks, in counterbalanced order. They predicted a peer after identifying the one piece of information (e.g., Round 1 performance) they wanted from that peer to base their prediction on. This was the information wanting task. In another task, a peer predicted participants' performance after participants had identified the one piece of information they wished to give the peer to use in making a prediction. This was the information giving task. The final task complemented this “giving” phase of the experiment by having participants assume the role of the “peer,” making a prediction of another participant's performance after being handed the one piece of information that this other participant wanted them to base their predictions on.   In this portion of the study, we wished to see whether participants would again be more likely to “give” aspiration-level information to a peer who was predicting them than they would be to “want” this same information when predicting a peer. We expected the opposite pattern for information about past performance. Participants would “want” this information when making predictions about a peer more than they would want to “give” this information to a peer who was predicting them. In addition, extending the findings of Study 1, we also checked to see whether people making predictions from aspiration-level data would prove to be more optimistic, and unrealistically so, than those working with information about past achievement.   In the part of the study replicating Study 2, participants were asked to predict their own Round 2 performance and a peer's Round 2 performance after being given full information about that peer's aspiration level and Round 1 achievement. We predicted that self-predictions would prove more overly optimistic than peer predictions and that this difference would arise, at least in part, because participants would weight aspiration level more and past performance less in their self-predictions than in their peer predictions. Like in Study 2, this would lead to gaps arising between self- and peer prediction when participants adopted high target levels or had posted low previous performances.   We also extended Study 2 by manipulating participants' aspiration level and past performance. We manipulated performance level by making the cup-stacking task more or less difficult. Some participants were given small cups that were easy to stack. Others were given larger cups that were more difficult to handle. Crossed with this manipulation was one aimed at influencing aspiration levels for Round 2 performance. Some participants were given rather low “target scores” to achieve to win cash prizes in Round 2; others were given higher target scores they had to hit to win money. These experimental variations allowed us to determine whether past performance and aspiration level played a causal role in the predictions that people offered about themselves, as well as the optimism they exhibited in these self-predictions.   Method   Participants   One hundred twenty-one participants completed the experiment for extra credit in their psychology courses.   Materials and procedure   The experiment consisted of one self-prediction and four peer prediction tasks, all administered within subjects. Due to the nature of the peer prediction conditions, each participant was yoked to four previous participants in the experiment.   Performance task   Participants, all run individually, were told they would take part in some “games of skill,” as well as making a number of performance predictions. Each participant began by completing a round of the main performance measure, a cup-stacking task modified from the popular NBC challenge show Minute to Win it. Participants were provided with 20 cups stacked upside down and were given 1 min to move as many cups from the bottom of the stack to the top. Participants could only move one cup at a time and were required to use alternating hands when stacking.   The experimenter explained the cup-stacking task to participants and gave them a moment to practice moving cups from the bottom of the stack to the top. Participants were informed that they would have an opportunity to win money in addition to their extra credit based on their performance on the cup-stacking task. To prevent participants from purposely underperforming on the first round, the experimenter did not explain the details of this incentive, merely saying that the details would be explained later and that the participant should just try to do as well as he or she could at the task. Once the participant understood, the experimenter took out a stopwatch, reminded participants of the 1-min time limit, and began the task, saying, “Ready… set… go!” After a minute, the experimenter stopped the participant and counted the number of cups stacked.   Difficulty manipulation   To control participants' performance on both rounds of the task, task difficulty was manipulated using two sizes of cups. In the low-difficulty condition, participants stacked small water cups (the sort found in dentists' offices for clients to rinse their mouths) in both rounds. In the high-difficulty condition, participants stacked larger plastic cups (the sort used at university parties for refreshments) in both rounds. Pretesting revealed that participants using the smaller cups were reliably better at the task than participants using the larger cups. This manipulation of difficulty allowed us to maintain the essential features of the task for all participants, while creating two performance groups in the least intrusive way possible. Participants were unaware of the fact that half their peers were assigned to a different difficulty condition.   Target-level manipulation   The experimenter then told participants they would take part in a second round of the cup-stacking task in a few minutes, with a chance to win up to $7 based on their performance. Participants were then presented with a list of three target scores. The lowest target had a potential pay-out of $3, the highest target had a potential pay-out of $7, and critically, the middle target (the value we expected most participants to gravitate toward) had the potential pay-out of $5. Participants' level of aspiration was manipulated by changing the number of cups associated with each payoff. In the low-target condition, participants chose between stacking 50, 55, or 60 cups. In the high-target condition, those values were shifted up five cups, to 55, 60, or 65 cups. Participants were asked to choose a target score, and payoff, for the second round. Participants were unaware of the fact that half their peers were assigned to a different target condition. One participant in the high-target condition chose a goal of 70 cups.   Prediction tasks   After choosing a target level, participants were told that they would complete a series of prediction tasks before confronting that second round of the cup-stacking task. Self-predictions always occurred first. The experimenter wrote the participant's Round 1 score on the top of a paper that included additional spaces for the participant's Round 2 target score, their prediction for Round 2, the amount of effort from −3 (Much less than Round 1) to 0 (The same as Round 1) to 3 (Much more than Round 1) they intended to exert for Round 2, and their confidence from 1 (Not at all) to 5 (Extremely) that they would be able to meet their goal.   Then, participants completed, in random order, four tasks relevant to peer prediction.   Replicating Study 1: Information Giving and Wanting   The next three tasks were replications of Study 1, in which participants were yoked to a different peer for each individual task. For each task, an accurate prediction (one falling within a 2.5% range of actual performance) earned the participant and his or her peer $2. In the information giving task, participants were told that a peer would predict the participant's own performance. Participants were told that the peer would only be given one piece of information on which to base the prediction and were asked which piece of information they wanted their peer to have to make the most accurate prediction. Participants chose from among their Round 1 performance (past behavior), their target performance, their effort rating, and their confidence rating. Participants also completed a task complementing the information giving task, in which they received a single piece of information selected by a peer and had to predict that peer's Round 2 performance.   In the information wanting task, participants were informed that they would make a prediction about a peer on the basis of one piece of information. Participants were given a choice about which piece of information they wanted from the four types listed above. Once chosen, the experimenter presented that piece of information to the participant, and he or she offered a prediction of his or her peer's performance.   Replicating Study 2: Peer Prediction With Full Information   This condition was a replication of the peer prediction task from Study 2. Participants were given the information sheet from another participant, which contained their Round 1 performance, their target score for Round 2, and their effort and confidence assessment (the peer's own prediction was hidden so that participants would not be swayed). Participants were instructed to make a prediction about how well their peer would do using whatever information they found valuable. Participants offered their prediction on a separate sheet of paper.   Round 2 performance   After they had completed all of the prediction tasks, participants completed Round 2 of the cup-stacking task. They were reminded of their past performance and their target for Round 2, and that if they surpassed the latter value, they would win $3, $5, or $7, depending on the value they had chosen. Participants were encouraged to perform as well as they could on the task. If participants beat their targets, they were compensated accordingly. All participants were then debriefed and thanked for their participation.   Results and Discussion   Data from four participants were excluded due to either experimenter error (one participant) or because they were statistical outliers in their Round 2 performance (one participant) or self-prediction (two participants), relative to other data in their experimental condition. Outliers were identified via a boxplot rule (Iglewicz & Hoaglin, 1993), with k = 1.5. Analyses were run on the remaining 117 participants. Note that the within-subjects yoked design required the first three participants and the last participant in the experiment to be unequally yoked to other participants in the experiment. Thus, analyses presented include all possible yoked pairs, resulting in anywhere from 112 to 116 comparisons per test.   Overview of the results   In Study 3, we sought to provide more extensive replications of Studies 1 and 2 using a paradigm that allowed us to experimentally control participants' past performance and aspiration level, to affirm that each influenced self-prediction. In addition, we examined whether people differed in the value they placed on target score versus past performance when they were predicting someone else versus when someone else was predicting them. In the second set of analyses, we explored whether differences in accuracy for self- and peer prediction could be explained by the weight given to past performance and aspiration-level data.   Replicating Study 1: Information Giving and Wanting   We first explored whether the information participants gave to their yoked peers, when the target of prediction was themselves, was the same as the information they requested from their peers when the target of prediction was that peer. Overall, participants displayed a preference for information about past behavior over information about aspiration level regardless of prediction target: 64% chose information about past performance, whereas 27% chose data about aspiration level. The remainder (9%) chose information about effort or comfort level with the material.   However, we predicted that this overall preference would be moderated by whom the prediction target was. Consistent with our predictions, we found that a greater proportion of participants (34%) gave target score information when the self was the target of prediction than wanted that same information (21%) when the task was to predict their peer's performance. We also found that participants were more likely to want past performance information (70%) when predicting a peer than they were to give it when the prediction target was the self (57%). To test whether this overall pattern was significant, we counted the number of participants who gave target score data to a peer but wanted past performance information when it came to predicting that peer. We also counted the number who did the opposite. As expected, the former number was greater than the latter (n = 26 vs. 10, p < .02, by sign test). These results suggest, replicating Study 1, that people see information about aspirations as more informative about the self than about peers, whereas information about past behavior is seen as more informative about peers than the self.   5   Effects of Information on Optimism   Did giving or receiving target score information versus past performance data have an impact on optimism and accuracy? Recall that in two of the prediction tasks administered in this study, participants made predictions on the basis of a single piece of information, either target performance or past behavior. As it turns out, the information that peers received or requested had a direct impact on the accuracy of the predictions they made.   First, each participant gave a yoked peer either target or past performance information, which the peer then used to make a prediction about the participant's performance. Those peers given target score information made more optimistic predictions than did those given information about past behavior (Ms = 55.28 and 52.09, SDs = 5.67 and 8.00, for target and past behavior information, respectively), t(103) = 2.19, p < .04, d = .47, although the effect of information on overoptimism (prediction minus performance) failed to be significant (Ms = 1.95 and 0.24, SDs = 9.37 and 9.52, for target and past behavior information, respectively), t(103) = 0.89, ns, d = .18. Second, each participant predicted the Round 2 performance of a peer, after having requested either target or past performance information. Those asking for target score information were more optimistic in their predictions than those asking about past behavior (Ms = 56.10 and 51.55, SDs = 4.74 and 9.34, for target and past performance, respectively), t(101) = 2.49, p < .02, d = .65, and such predictions proved to be more unrealistically optimistic to a significant degree (Ms = 5.41 and 0.42, SDs = 10.82 and 11.22, respectively), t(101) = 2.05, p < .05, d = .45. To examine these effects more comprehensively, we combined the data from these two rounds of prediction. The resulting analyses suggest that making predictions with target score led to more optimistic predictions (Z = 3.26, p < .002), ones that were more overly optimistic relative to reality (Z = 2.06, p < .04) than working with knowledge of past behavior.   6   Replicating Study 2: Accuracy of Self- Versus Peer predictions   In the phase of the study serving as a replication of Study 2, we conducted two analyses to assess the accuracy of self- and peer predictions. First, once again, self- and peer predictions given full information displayed virtually identical relationships to actual performance, both rs(115) = .60, p < .0001. However, self-predictions (M = 54.18, SD = 7.69) were more optimistic compared with peer predictions (M = 53.22, SD = 7.67), t(116) = 1.97, p = .05, d = .20, and actual performance (M = 52.15, SD = 8.25), t(116) = 3.05, p < .005, d = .57. Peer predictions did not significantly differ from actual performance, t(116) = 1.61, p < .12.   Impact of Target and Difficulty Conditions on Performance and Target Score   As manipulation checks, we examined the impact of target and difficulty manipulations on participants' past (i.e., Round 1) performance and the target score they set for themselves in Round 2, conducting two 2 (target: high vs. low) × 2 (difficulty: low vs. high) analyses of variance. These analyses revealed, in Round 1, that participants posted higher performances in the low-difficulty condition than in the high-difficulty condition (Ms = 50.07 and 39.26, SDs = 7.14 and 7.15, respectively), F(1, 113) = 66.53, p < .0001, d = 1.51. Round 1 performance was equivalent across target conditions (F = 0.06, ns, d = .09).   In terms of the target scores participants set, both target and difficulty conditions had an impact. Participants set higher targets in the high-target than in the low-target condition (Ms = 57.97 and 54.19, SDs = 3.36 and 4.05, respectively), F(1, 113) = 31.60, p < .0001, d = 1.03. Participants also set higher targets in the low-difficulty condition than in the high-difficulty one (Ms = 57.25 and 54.88, SDs = 4.46 and 3.47, respectively), F(1, 113) = 11.89, p < .001, d = .58.   Impact of Target and Difficulty Conditions on Self- and Peer Prediction   Target and difficulty conditions also had an impact on self-predictions as well as on how overly optimistic self-predictions were compared with actual scores in Round 2. Self-predictions were sensitive to difficulty condition: Participants offered more optimistic predictions in the low-difficulty condition (M = 57.61, SD = 5.44) than in the high-difficulty condition (M = 50.56, SD = 8.09), F(1, 114) = 31.26, p < .0001, d = 1.04. However, the effect of the difficulty condition on self-predictions underestimated its actual effect on Round 2 performance. Participants in the high-difficulty condition performed significantly worse (M = 46.77, SD = 6.70) in Round 2 than participants in the low-difficulty condition (M = 57.05, SD = 5.87), F(1, 114) = 78.84, p < .0001, d = 1.64. Because participants underestimated the effect of the difficulty condition on performance, those in the high-difficulty condition showed greater overoptimism (i.e., predicted minus actual performance) than participants in the low-difficulty one (Ms = 3.81 and 0.30, SDs = 7.71 and 6.21, for high- and low-difficulty conditions, respectively), F(1, 114) = 7.49, p < .01, d = .49.   Independent of these effects, self-predictions were influenced by target condition (Ms = 55.60 and 52.72, SDs = 8.45 and 6.59 for high and low conditions, respectively), F(1, 114) = 4.56, p < .04, d = .39. This influence was unwarranted because target condition had no effect on participants' Round 2 performance (Ms = 52.39 and 51.91, SDs = 8.50 and 8.05 for high- and low-target groups, respectively), F(1, 114) = 0.02, ns, d = .04. This prompted participants to be more overly optimistic in the high-target condition than in the low-target one (Ms = 3.21 and 0.81, SDs = 7.75 and 6.36, for high- and low-target conditions, respectively), F(1, 114) = 3.77, p = .05, d = .35. In sum, self-predictions were influenced by both conditions, but imperfectly so. Self-predictions were not sensitive enough to task difficulty, and were too sensitive to target condition.   In contrast, peer predictions were affected only by the difficulty condition (Ms = 56.67 and 49.52, SDs = 6.20 and 7.36, for low- and high-difficulty conditions, respectively), F(1, 114) = 32.83, p < .0001, d = 1.06. Target condition had no effect on peer predictions (Ms = 54.10 and 53.32, SDs = 8.21 and 7.02, for high- and low-target conditions, respectively), F(1, 114) = 1.54, ns, d = .10. In this, peer predictions better mimicked reality, in that it was only the difficulty condition that influenced participants' actual performance in Round 2. However, peer predictions did not perfectly weight the difficulty condition, in that peers showed more overoptimism, relative to actual performance, in the high-difficulty condition than in the low-difficulty one (Ms = 2.75 and −0.53, SDs = 7.67 and 6.34, for high- and low-difficulty conditions, respectively), F(1, 114) = 6.50, p < .02, d = .47.   In sum, these findings suggest that self-predictions were influenced by both the difficulty of the task and the aspirations participants set—both past performance and aspiration level played a causal role in self-prediction—but that peer predictions were affected only by the task difficulty. In that, peer predictions better matched the impact of difficulty and target conditions on actual performance.   Weight Given to Target Score and Past Performance Information   The next step in these analyses was to explore whether any difference in the weight given to target and past performance information explained the difference in overoptimism between self- and peer prediction, in much the same way it did in Study 2.   7   We began by regressing self-predictions on target score and Round 1 performance and discovered again that participants misweighted these two variables. As seen in Table 3, the weight participants gave to target information (β = .37, p < .01) was much higher than the actual nonsignificant relationship we observed between target score and actual Round 2 performance (β = .02). The weight they gave to past performance (β = .58, p < .0001) lay closer to the actual relationship between Round 1 and Round 2 performance (β = .69, p < .0001). In contrast, the weight that participants gave to these variables in peer prediction lay closer to their actual relationship to Round 2 performance (bs = .15, p < .01, and .75, p < .0001, for target score and past performance, respectively).   As seen in Table 3 and Figure 2, this misweighting exacerbated overoptimism in self-prediction. Overoptimism (predicted minus actual Round 2 performance) in self-prediction correlated positively with target score. That is, participants displayed the most overoptimism when they set high target scores (β = .37, p < .001). Beyond this, overoptimism correlated marginally with Round 1 performance (β = −.19, p < .08).   In terms of comparative optimism (i.e., self- minus peer prediction), both variables were implicated. As seen in the top panel of Figure 2, self-predictions were more optimistic than peer predictions to the extent that participants set high targets for themselves (β = .30, p < .01), controlling for Round 1 performance. In addition, the optimism of self-predictions exceeded that of peer predictions to the extent that past performance was low (β = −.26, p < .02), as evidenced in the bottom panel of Figure 2. That is, participants discounted their own past achievement when that achievement was low, relative to what their peers made of it, controlling for which target scores were adopted.   Summary   These results provide conceptual replications of the first two studies, using a novel laboratory task with built-in manipulations of both past performance and aspiration level. The choices participants made in giving versus wanting of information revealed that they thought target score information more valuable for predicting the self than a peer, whereas past behavior was more important for predicting a peer than one's self. This pattern replicated Study 1. Importantly, Study 3 also revealed that peers predicting from target score information made more optimistic predictions overall than did those working with data about past behavior.   Replicating Study 2, participants showed more optimism in self-prediction than in peer prediction, even when working from the same information. When provided full information about both target score and past achievement, participants gave greater weight to target score in self-prediction than they did in peer prediction, and weighted past achievement data more in peer rather than in self-prediction. In this, Study 3 replicated the findings of Study 2.   Of key import, Study 3 also showed that aspiration level and past performance played a causal role in shaping self-prediction and the overoptimism—at least relative to future performance actually achieved—associated with it. Participants induced to adopt higher, versus lower, target scores produced more optimistic predictions that exceeded actual subsequent performance. Participants induced to perform badly lowered their predictions, albeit not enough, leaving them to be more optimistic than participants induced to perform more impressively.   8   General Discussion   Why and when do people show greater insight into the future behavior of another person than they do their own? In the present article, peer predictions made on the basis of limited information equaled or outperformed self-predictions, depending on which metric of accuracy one looked at. After being furnished with a small amount of relevant information, the prediction of peers correlated just as strongly as self-predictions did with future performance, for both familiar (exam performance) and novel (cup-stacking) tasks. Peer predictions, however, showed their superiority over self-predictions in that they, at least in part, avoided the overoptimism so often found in self-prediction (Z = 3.22, p < .002), combining Studies 2 and 3.   This difference in accuracy could be surprising for at least two reasons. First, peers had only a small amount of second-hand and incomplete information upon which to base their predictions, whereas the self had a seemingly limitless supply of first-hand knowledge relevant to future performance. Second, peer predictors were passive observers to an unknown other's fate; self-predictors, though, had a degree of control over both their past and future performance. MacDonald and Ross (1999; see also Sherman, 1980) have referred to this as the “self-erasing” feature of prediction error. Presumably, self-predictors can conform their behavior to a plan (study more, stack faster) so that whatever outcome is predicted becomes more likely to actually occur. Nonetheless, our studies join a small group of other empirical efforts (e.g., Epley & Dunning, 2006) that show that peers are often equal to the self when one looks at accuracy in terms of correlation and superior to the self when gauged in terms of overoptimism.   The Triumph of Hope Over Experience   The difference in overoptimism between self- and peer prediction was linked in all three studies to divergent strategies used by self and other to predict the future. In peer prediction, the past was prologue. People looked more intently on another person's past performance when gauging their future than they looked toward their own when predicting the self. In Studies 1 and 3, participants requested past behavior as a guide to peer predictions more often than they provided that information to a peer who was predicting them. In Studies 2 and 3, peers gave greater weight to past performance when predicting other people than when predicting the self. Indeed, the weight they gave past performance mirrored its actual relationship to future achievement.   However, for the self, information about past behavior was discounted in favor of agentic information, in particular, information about aspiration level—something of a triumph of hope over experience (Massey et al., 2011). When given the opportunity to win money by leading their peers to an accurate prediction about their future performance (Studies 1 and 3), people passed on information about their aspirations much more readily than they accepted it from another person. In Study 3, peers receiving this information were led to predictions that better mimicked the self, but predictions that ultimately strayed optimistically from reality. It is important to note that in two of the three studies presented here, the very same people who showed wisdom in asking for behavioral information as a guide to their peer predictions tended to discount the value of that same information for self-prediction. In other words, although people had insight about how best to predict their peers, they failed to apply that insight to forecasting themselves.   When it came to actually forming predictions of future behavior, self-predictors gave greater weight to information about aspiration level across Studies 2 and 3 (Z = 4.63, p < .0001) and lesser weight to past behavior (Z = −4.16, p < .0001) than their peers did. This different, and inappropriate, weighting of aspiration level and past behavior produced the circumstances in which self-prediction proved too optimistic relative to peer prediction. When participants set lofty goals (i.e., high target scores) for themselves, they were much more optimistic than their peers and their actual performance. When participants posted lackluster past performance, their discounting of that performance led them to levels of optimism that, again, surpassed any expressed by their peers or found in their actual performance.   This asymmetric focus on aspiration for the self we argue is a reflection of agency bias, in which people give too much weight in self-prediction to their intentions, goals, plans, efforts, and force of personality. In our studies, the faith participants placed in their own agency (as measured both by their willingness to pass it on to their peers and by the weight they gave it in their self-predictions) was far greater than our regression analyses said it ought to have been. Across studies, participants discounted relevant behavioral information (which was a valid predictor of behavior) in favor of their aspirations, and their predictions suffered because of it.   Perseverance of Incompetence   These data also suggest a potential explanation for a curious finding discovered elsewhere in the literature on self-assessment. Dunning and colleagues (Dunning, 2011; Kruger & Dunning, 1999) have demonstrated that incompetent performers, those performing the worst among peers, tend not to possess much insight into the deficiencies of their performances. Kruger and Dunning attributed this lack of insight to lack of intellectual resources—the gaps in knowledge and expertise that lead these performers to perform poorly also prevent them from recognizing the inferiority of their performances and the superiority of others.   What is curious, however, is what happens when people are given feedback about their poor performances. This tends not to lead people in general (Ferraro, 2010; Massey, Simmons, & Armor, 2011) or poor performers specifically (Hacker, Bol, Horgan, & Rakow, 2000) to reach more accurate self-assessments. The curiosity is not that people fail to recognize their deficits; it is that feedback fails to lead people toward either better performance or more accurate self-insight. Instead, people seem to choose to dwell in blissful ignorance of their incompetence.   The data herein present one avenue by which poor performers might maintain unrealistic views of their potential for achievement even with clear feedback. They discount poor past performances because of a reliance on agentic principles. They set goals, plans, and intentions that they believe will enhance their future achievement. As a consequence, relative to peers, they fail to recognize just how diagnostic past behavior is for anticipating future performance.   This reliance on agency might suggest other ways in which poor performers may remain unknowing. People who believe too strongly in their own agency are likely to forgo external aids that can help them achieve better outcomes. In research on budgeting, for example, people turned down the use of an aid that could help them track whether they reached their budgetary goals (Koehler et al., 2011), although such an aid was valuable to those who used it. Sheldon and colleagues (Sheldon, Ames, & Dunning, 2011) found that poor performers on a test of emotional intelligence largely rejected a chance to buy a book at a discounted price on improving one's emotional intelligence, whereas their better performing peers snatched it up. Of those in the bottom quartile, only 20% bought the book. Of those in the top quartile, 64% did. Refusing the book was related to narcissism among bottom performers, indicating an esteem-defensive motive for the choice.   Strategies for Accuracy   Magic mirror, if we only could   Try to see ourselves as others would   —Leon Russell (1972)   Although it is still an open question whether overoptimism or realism provides ultimate benefit or harm to psychological well-being, what is uncontroversial is that sometimes people need accuracy in their self-assessments. The student who must decide whether to drop a course before the deadline, the CEO who sticks her neck out to promise a product shipment by a certain date, the problem drinker who opts to tackle this addiction using nothing but sheer willpower are people in whom the presence of an agency bias may impede good judgment, leading to more harm than good.   The good news from our data is that the truth (or something closer to it) is more knowable than first-pass self-predictions allow. People can achieve greater self-insight about their futures, though the trick is that they must be able to see themselves as others see them, as agents whose future behavior is tied to the past and whose future potential is limited by internal and external constraints. Four strategies might allow for this kind of dispassionate self-insight.   The first is for people to ask themselves “How would someone else expect me to perform?” or the related question, “If someone else had the same performance record and goals as I do, how would I expect them to perform?” This kind of third-person perspective on one's self has been shown to improve the relationship between predicted and actual behavior across a number of domains (Armor & Sackett, 2006; Buehler, Griffin, Lam, & Deslauriers, 2012; Libby, Shaeffer, Eibach, & Slemmer, 2007).   A second strategy would be to stick to actuarial predictions, ignoring the target of prediction altogether. Taking the average of past performance and allowing for a reasonable margin of error will result in accurate predictions much of the time. With that in mind, it is interesting that in Study 2, performances on a previous exam were more tightly correlated with actual exam performance, r(95) = .49, p < .0001, than participants self-predictions were, r(96) = .40, p < .0001. In addition, whereas self-predictions were overly optimistic by 5.6%, Exam 1 scores underestimated the same performance by only 2.7%. Thus, in terms of correlation and in terms of optimism/pessimism, participants in Study 2 would have been more accurate in their predictions if they had just predicted repeating their previous exam score.   The third, and most indirect, strategy to self-insight is to ask another person to predict one's own future behavior. This strategy has the advantage of relying on a more unbiased source of assessment, but the disadvantage of being externally generated, and thus easy to discard if the conclusion is not favorable to one's desires. Still, in some cases, wisdom from close others or from professionals can be absolutely necessary for guiding people toward an acknowledgment of their past behavior and toward tempering their overly agentic predictions. There is evidence that simply the act of considering a prediction other than one's own initial response can result in estimates that are less prone to bias and overconfidence (Herzog & Hertwig, 2009; Koehler, 1994; Lord, Lepper, & Preston, 1984).   The final strategy is to be mindful of when self-predictions are most likely to be erroneous, relative to peer prediction and reality. We found that participants were the most wrong about their achievement when they adopted high levels of aspiration or when their previous performance had been poor. In the first case, participants gave too much credence to their high levels of aspiration. In the second, they discounted too much the diagnostic value of previous bad performance. Our data suggest these are situations in which people could gain in predictive accuracy by adjusting their predictions or by consulting their peers.   Of course, these strategies will be most helpful when people are particularly prone to an agency bias. As our data suggest, when people have demonstrated sufficient mastery in the domain or when the goals they set are modest, they will be less susceptible to overoptimism in their predictions. The catch, however, is that it is precisely in domains people are likely to care most about (i.e., those for which their aspirations are high) where they are most likely to fall prey to an agency bias, forgetting past behavior, and leading them toward self-assessment errors in the very domains where accurate self-assessment is important.   Concluding Remarks   The belief that the self is an agentic being free from the constraints of past behavior and bounded only by aspiration leads people to potentially detrimental errors in self-prediction. People do not commit these same errors for their peers, primarily because they see their peers as less agentic and more constrained by past behavior. It is as Henry Wadsworth Longfellow observed, “We judge ourselves by what we feel capable of doing, while others judge us by what we have already done.” What he failed to mention is that for those interested in anticipating the truth of future behavior, the second strategy appears to be not only wise, but perhaps the more enlightened path.   1   A careful reader may wonder whether participants would feature aspiration level too much in their self-predictions merely because they fail to distinguish between the performance they wish to obtain (i.e., their aspiration level) and the performance they are likely to obtain. Past work shows that respondents easily distinguish between aspiration and expectation of future behavior (Gordon, 1990; Warshaw & Davis, 1985) and approach providing reports of each differently. Such reports may be related, but they are not conflated.   2   Importantly, the ranking participants gave to their own past exam score did not correlate significantly with the quality of that score (r = −.25, ns), nor did the discrepancy in ranking given to past versus target score (r = .04, ns). This rules against an alternative explanation that participants avoided giving peers their past exam scores merely out of embarrassment when those scores were low.   3   In an alternative analysis, we regressed self-predictions on actual performance and peer predictions and submitted the residuals to analyses similar to those reported here. These analyses provide the same statistical conclusions as those reported here.   4   Although we found that setting a high target score was associated with prediction error, one might argue that setting a high bar may still be the right thing to do. Although giving undue weight to lofty aspirations may lead people astray in their forecasts, this kind of self-insight error might be tolerable if setting such goals prompts them to perform at a higher level than they might otherwise have done. That is, setting high goals may energize people to greater success, if not the success they initially expected (Gollwitzer, 1990; Latham & Baldes, 1975). Our data, however, provide no support for this idea. In Study 2, higher target scores were, indeed, associated with higher Exam 2 performance (β = .38, p < .0001), but not after past performance was controlled for (β = .17, p = .11). In short, if higher target scores were related to higher performance, then it is not because more optimistic targets led to improved performance. Rather, the relation between target score and performance reflected past behavior, not any active motivating role played by optimism.   5   The preference to give target versus past performance information when the self was the prediction target was not associated with participants' Round 1 score (r   pb = −.10, ns). Thus, we again found no evidence that participants' reluctance to give others information about past performance was prompted by the potential embarrassment of having a low score.   6   From these analyses, we omitted those cases in which participants opted to have information about effort or comfort level passed along (ns = 11 and 10, respectively, in the two analyses presented in the text).   7   One participant's data were disproportionally influential in the multiple regression predicting overoptimism from target score and Round 1 performance (Cook's distance d = .18 for both overoptimism measures) over the threshold (.034) suggested by Bollen and Jackman (1990) for n = 117. Thus, this participant's data were omitted from the analysis reported in the text.   8   Did setting high goals lead to enhanced performance (Gollwitzer, 1990)? As in Study 2, we found that high target scores, again, were related to higher cup-stacking performance on Round 2 (β = .38, p < .0001), but not after Round 1 performance was accounted for (β = .02, ns). That is, target scores had no relation to Round 2 performance over and above the information provided by previous achievement. Thus, our data suggest that high aspirations, in of themselves, are not sufficient causes of enhanced performance. To be sure, they may be a necessary condition, in that setting a low goal may prompt a person to achieve less, but the mere act of setting a high goal does not automatically improve performance (see also Buehler et al., 1997; Peetz & Buehler, 2009; Peetz & Kammrath, 2011).   References   Aarts, H.   ,    Custers, R.   , &    Marien, H.   (2009). Priming and authorship ascription: When nonconscious goals turn into conscious experiences of self-agency. Journal of Personality and Social Psychology, 96, 967–979. doi:10.1037/a0015000   Andersen, S. M.   , &    Ross, L.   (1984). Self-knowledge and social inference: I. The impact of cognitive/affective and behavioral data. Journal of Personality and Social Psychology, 46, 280–293. doi:10.1037/0022-3514.46.2.280   Armor, D. A.   , &    Sackett, A. M.   (2006). Accuracy, error, and bias in predictions for real versus hypothetical events. Journal of Personality and Social Psychology, 91, 583–600. doi:10.1037/0022-3514.91.4.583   Balcetis, E.   (2009). How a biased majority claim a moral minority: Tracking eye movements to base rates in social predictions. Journal of Experimental Social Psychology, 45, 970–973. doi:10.1016/j.jesp.2009.02.018   Balcetis, E.   , &    Dunning, D.   (2008). A mile in moccasins: How situational experience diminishes dispositionism in social inference. Personality and Social Psychology Bulletin, 34, 102–114. doi:10.1177/0146167207309201   Balcetis, E.   , &    Dunning, D.   (in press). Considering the situation: Why people are better social psychologists than self-psychologists. Self and Identity.   Balcetis, E.   ,    Dunning, D.   , &    Miller, R.   (2008). Do collectivists “know themselves” better than individualists? Cross-cultural studies of the holier than thou phenomenon. Journal of Personality and Social Psychology, 95, 1252–1267. doi:10.1037/a0013195   Bass, B. M.   , &    Yammarino, F. J.   (1991). Congruence of self and others' leadership ratings of Naval officers for understanding successful performance. Applied Psychology, 40, 437–454. doi:10.1111/j.1464-0597.1991.tb01002.x   Baxter, T. L.   , &    Goldberg, L.   (1987). Perceived behavioral consistency underlying trait attributions to oneself and another: An extension of the actor-observer effect. Personality and Social Psychology Bulletin, 13, 437–447. doi:10.1177/0146167287134001   Bollen, K. A.   , &    Jackman, R.   (1990). Regression diagnostics: An expository treatment of outliers and influential cases. In    J.   Fox   &    J.   Scott   (Eds.), Modern methods of data analysis (pp. 257–291). Newbury Park, CA: Sage.   Buehler, R.   ,    Griffin, D.   ,    Lam, K. C. H.   , &    Deslauriers, J.   (2012). Perspectives on prediction: Does third-person imagery improve task completion estimates?   Organizational Behavior and Human Decision Processes, 117, 138–149.   Buehler, R.   ,    Griffin, D.   , &    MacDonald, H.   (1997). The role of motivated reasoning in optimistic time predictions. Personality and Social Psychology Bulletin, 23, 238–247. doi:10.1177/0146167297233003   Buehler, R.   ,    Griffin, D.   , &    Ross, M.   (1994). Exploring the “planning fallacy”: Why people underestimate their task completion times. Journal of Personality and Social Psychology, 67, 366–381. doi:10.1037/0022-3514.67.3.366   Diener, E.   , &    Larsen, E. J.   (1984). Temporal stability and cross-situational consistence of affective, behavioral, and cognitive responses. Journal of Personality and Social Psychology, 47, 871–883. doi:10.1037/0022-3514.47.4.871   Dunning, D.   (2005). Self-insight: Roadblocks and detours on the path to knowing thyself. New York, NY: Psychology Press. doi:10.4324/9780203337998   Dunning, D.   (2011). The Dunning–Kruger effect: On being ignorant of one's own ignorance. In    M. P.   Zanna   (Ed.), Advances in experimental social psychology (Vol. 44, pp. 247–296). New York, NY: Elsevier.   Dunning, D.   ,    Heath, C.   , &    Suls, J.   (2004). Flawed self-assessment: Implications for health, education, and the workplace. Psychological Science in the Public Interest, 5, 69–106. doi:10.1111/j.1529-1006.2004.00018.x   Epley, N.   , &    Dunning, D.   (2000). Feeling “holier than thou”: Are self-serving assessments produced by errors in self- or social prediction?   Journal of Personality and Social Psychology, 79, 861–875. doi:10.1037/0022-3514.79.6.861   Epley, N.   , &    Dunning, D.   (2006). The mixed blessings of self-knowledge in behavioral prediction: Enhanced discrimination but exacerbated bias. Personality and Social Psychology Bulletin, 32, 641–655. doi:10.1177/0146167205284007   Ferraro, P. J.   (2010). Know thyself: Competence and self-awareness. Atlantic Economic Journal, 38, 183–196. doi:10.1007/s11293-010-9226-2   Gollwitzer, P. M.   (1990). Action phases and mind-sets. In    E. T.   Higgins   &    R. M.   Sorrentino   (Eds.), The handbook of motivation and cognition: Foundations of social behavior (Vol. 2, pp. 53–92). New York, NY: Guilford Press.   Gordon, R. A.   (1990). Informational bases of behavioral intentions and behavioral expectations on self-predictions. Basic and Applied Social Psychology, 11, 433–442. doi:10.1207/s15324834basp1104_6   Hacker, D. J.   ,    Bol, L.   ,    Horgan, D. D.   , &    Rakow, E. A.   (2000). Test prediction and performance in a classroom context. Journal of Educational Psychology, 92, 160–170. doi:10.1037/0022-0663.92.1.160   Hall, C. C.   ,    Ariss, L.   , &    Todorov, A.   (2007). The illusion of knowledge: When more information reduces accuracy and increases confidence. Organizational Behavior and Human Decision Processes, 103, 277–290. doi:10.1016/j.obhdp.2007.01.003   Herzog, S. M.   , &    Hertwig, R.   (2009). The wisdom of many in one mind: Improving individual judgments with dialectical bootstrapping. Psychological Science, 20, 231–237. doi:10.1111/j.1467-9280.2009.02271.x   Iglewicz, B.   , &    Hoaglin, D. C.   (1993). How to detect and handle outliers. Milwaukee, WI: American Society for Quality Control.   Koehler, D. J.   (1994). Hypothesis generation and confidence in judgment. Journal of Experimental Psychology: Learning, Memory, and Cognition, 20, 461–469. doi:10.1037/0278-7393.20.2.461   Koehler, D. J.   , &    Poon, C. S. K.   (2006). Self-predictions overweight the strength of current intentions. Journal of Experimental Social Psychology, 42, 517–524. doi:10.1016/j.jesp.2005.08.003   Koehler, D. J.   ,    White, R. J.   , &    John, L. K.   (2011). Good intentions, optimistic self-predictions, and missed opportunities. Social Psychological and Personality Science, 2, 90–96. doi:10.1177/1948550610375722   Kolar, D. W.   ,    Funder, D. C.   , &    Colvin, C. R.   (1996). Comparing the accuracy of personality judgments by the self and knowledgeable others. Journal of Personality, 64, 311–337. doi:10.1111/j.1467-6494.1996.tb00513.x   Kruger, J.   , &    Dunning, D.   (1999). Unskilled and unaware of it: How difficulties in recognizing one's own incompetence lead to inflated self-assessments. Journal of Personality and Social Psychology, 77, 1121–1134. doi:10.1037/0022-3514.77.6.1121   Kruger, J.   , &    Gilovich, T.   (2004). Actions and intentions in self-assessments: The road to self-enhancement is paved with good intentions. Personality and Social Psychology Bulletin, 30, 328–339. doi:10.1177/0146167203259932   Langer, E. J.   (1975). The illusion of control. Journal of Personality and Social Psychology, 32, 311–328. doi:10.1037/0022-3514.32.2.311   Latham, G. P.   , &    Baldes, J. J.   (1975). The “practical significance” of Locke's theory of goal setting. Journal of Applied Psychology, 60, 122–124. doi:10.1037/h0076354   Libby, L. K.   ,    Shaeffer, E. M.   ,    Eibach, R. P.   , &    Slemmer, J. A.   (2007). Picture yourself at the polls: Visual perspective in mental imagery affects self-perception and behavior. Psychological Science, 18, 199–203. doi:10.1111/j.1467-9280.2007.01872.x   Lord, C. G.   ,    Lepper, M. R.   , &    Preston, E.   (1984). Considering the opposite: A corrective strategy for social judgment. Journal of Personality and Social Psychology, 47, 1231–1243. doi:10.1037/0022-3514.47.6.1231   MacDonald, T. K.   , &    Ross, M.   (1999). Assessing the accuracy of predictions about dating relationships: How and why do lovers' predictions differ from those made by observers?   Personality and Social Psychology Bulletin, 25, 1417–1429. doi:10.1177/0146167299259007   Malle, B. F.   (2005). Self-other asymmetries in behavior explanations: Myth and reality. In    M. D.   Alicke   ,    D. A.   Dunning   , &    J. I.   Krueger   (Eds.), The self in social judgment: Studies in self and identity (pp. 155–178). New York, NY: Psychology Press.   Massey, C.   ,    Simmons, J. P.   , &    Armor, D. A.   (2011). Hope over experience: Desirability and the persistence of optimism. Psychological Science, 22, 274–281. doi:10.1177/0956797610396223   Mehl, M. R.   , &    Pennebaker, J. W.   (2003). The sounds of social life: A psychometric analysis of students' daily social environments and natural conversations. Journal of Personality and Social Psychology, 84, 857–870. doi:10.1037/0022-3514.84.4.857   Newby-Clark, I. R.   ,    Ross, M.   ,    Buehler, R.   ,    Koehler, D. J.   , &    Griffin, D.   (2000). People focus on optimistic scenarios and disregard pessimistic scenarios while predicting task completion times. Journal of Experimental Psychology: Applied, 6, 171–182. doi:10.1037/1076-898X.6.3.171   Nezlek, J. B.   (1993). The stability of social interaction. Journal of Personality and Social Psychology, 65, 930–941. doi:10.1037/0022-3514.65.5.930   Osberg, T. M.   , &    Shrauger, J. S.   (1986). Self-prediction: Exploring the parameters of accuracy. Journal of Personality and Social Psychology, 51, 1044–1057. doi:10.1037/0022-3514.51.5.1044   Ouellette, J. A.   , &    Wood, W.   (1998). Habit and intention in everyday life: The multiple processes by which past behavior predicts future behavior. Psychological Bulletin, 124, 54–74. doi:10.1037/0033-2909.124.1.54   Peetz, J.   , &    Buehler, R.   (2009). Is there a budget fallacy? The role of savings goals in the prediction of personal spending. Personality and Social Psychology Bulletin, 35, 1579–1591. doi:10.1177/0146167209345160   Peetz, J.   , &    Kammrath, L.   (2011). Only because I love you: Why people make and why they break promises in romantic relationships. Journal of Personality and Social Psychology, 100, 887–904. doi:10.1037/a0021857   Pronin, E.   (2008, May   30). How we see ourselves and how we see others. Science, 320, 1177–1180. doi:10.1126/science.1154199   Pronin, E.   ,    Berger, J.   , &    Molouki, S.   (2007). Alone in a crowd of sheep: Asymmetric perceptions of conformity and their roots in an introspection illusion. Journal of Personality and Social Psychology, 92, 585–595. doi:10.1037/0022-3514.92.4.585   Pronin, E.   , &    Kugler, M. B.   (2007). Valuing thoughts, ignoring behavior: The introspective illusion as a source of the bias blind spot. Journal of Experimental Social Psychology, 43, 565–578. doi:10.1016/j.jesp.2006.05.011   Pronin, E.   , &    Kugler, M. B.   (2010). People believe they have more free will than others. Proceedings in the National Academy of Sciences, 107, 22469–22474. doi:10.1073/pnas.1012046108   Risucci, D. A.   ,    Tortolani, A. J.   , &    Ward, R. J.   (1989). Ratings of surgical residents by self, supervisors and peers. Surgical Gynecology and Obstetrics, 169, 519–526.   Russell, L.   (1972). Magic mirror. On Carney [CD]. Tulsa, OK: Shelter.   Sheldon, O. J.   ,    Ames, D. R.   , &    Dunning, D.   (2011). Emotionally unskilled, unaware, and disinterested in learning more: Biased assessments of emotional intelligence. Unpublished manuscript, Rutgers University.   Sherman, S. J.   (1980). On the self-erasing nature of errors of prediction. Journal of Personality and Social Psychology, 39, 211–221. doi:10.1037/0022-3514.39.2.211   Shrauger, J. S.   , &    Osberg, T. M.   (1981). The relative accuracy of self-predictions and predictions by others in psychological assessment. Psychological Bulletin, 90, 322–351. doi:10.1037/0033-2909.90.2.322   Spain, J. S.   ,    Eaton, L. G.   , &    Funder, D. C.   (2000). Perspectives on personality: The relative accuracy of self vs. others for the prediction of behavior and emotion. Journal of Personality, 68, 837–867. doi:10.1111/1467-6494.00118   Vazire, S.   (2010). Who knows what about a person? The Self-Other Knowledge Asymmetry (SOKA) model. Journal of Personality and Social Psychology, 98, 281–300. doi:10.1037/a0017908   Vazire, S.   , &    Mehl, M. R.   (2008). Knowing me, knowing you: The accuracy and unique predictive validity of self-ratings and other-ratings of daily behavior. Journal of Personality and Social Psychology, 95, 1202–1216. doi:10.1037/a0013314   Warshaw, P. R.   , &    Davis, F. D.   (1985). Disentangling behavioral intention and behavioral expectation. Journal of Experimental Social Psychology, 21, 213–228. doi:10.1016/0022-1031(85)90017-4   Wegner, D. M.   (2002). The illusion of conscious will. Cambridge, MA: MIT Press.   Weinstein, N. D.   (1980). Unrealistic optimism about future life events. Journal of Personality and Social Psychology, 39, 806–820. doi:10.1037/0022-3514.39.5.806   Williams, E. F.   , &    Gilovich, T.   (2008). Conceptions of the self and others across time. Personality and Social Psychology Bulletin, 34, 1037–1046. doi:10.1177/0146167208317603   Williams, E. F.   ,    Gilovich, T.   , &    Dunning, D.   (2012). Being all that you can be: How potential performances influence assessments of self and others. Personality and Social Psychology Bulletin, 38, 143–154.   Wilson, T. D.   , &    Gilbert, D. T.   (2003). Affective forecasting. Advances in Experimental Social Psychology, 35, 345–411. doi:10.1016/S0065-2601(03)01006-2   1   Key Questions Asked of Students for Predicting Exam Performance, Studies 1 and 2   Question   Answer format   M   SD   Note. Means and standard deviations are from Study 2, in which peer predictors were provided with full information. HD = human development; GPA = grade point average.   a Corresponds to past performance. b Corresponds to aspiration level.   How many total psychology or human development courses have you taken in the past?   Open ended   2.5   2.9   Are you a psychology/HD major?   Yes/No/Considering   Yes: 40%   No: 43%   Considering: 17%   Are you taking this class for a letter grade or pass/fail?   Letter grade/Pass-fail   Letter: 93%   Pass/fail: 7%   What is your average grade (or GPA) in psychology/human development courses?   Open ended, given as a number between 0 and 4.3   3.6   0.5   What was your Prelim [Exam] 1 score for this course?a   Open ended, given as a percent   77.8   10.8   What is your target score for the exam? What percent of the points is your goal for the second exam?b   Open ended, given as a percent   89.6   6.1   How much effort do you intend to exert in preparation for this exam, relative to exams in other classes?   1 (Much less effort than usual) to 7 (Much more effort than usual)   5.3   1.3   How comfortable are you with the material in this course?   1 (Not at all comfortable) to 7 (Very comfortable)   5.3   0.9   How important is it to you that you meet your performance goal for this exam?   1 (Not at all) to 7 (Extremely)   5.4   1.4   What percentage of points do you think you will get on Prelim [Exam] 2?   Open ended, given as a percent   86.2   6.7   2   Relationship of Target Score (Standardized Regression Coefficients) and Previous Performance to Self-Prediction, Peer Prediction, Actual Performance, as Well as Indices of Undue Optimism (Study 2)   Variable   Information   Target score   Previous score   Self-prediction   .68   .21   Peer prediction   .27   .62   Actual performance   .17   .40   Self overoptimism   Self-prediction minus actual performance   .28   −.28   Self-prediction minus peer prediction   .45   −.47   Peer overoptimism   Peer-prediction minus actual score   .00   −.00   3   Relationship (Standardized Regression Coefficients) of Target Score and Previous Performance to Self-Prediction, Peer Prediction, Actual Performance, as Well as Indices of Undue Optimism (Study 3)   Variable   Information   Target score   Previous score   Self-prediction   .37   .58   Peer prediction   .15   .75   Actual performance   .02   .69   Self overoptimism   Self-prediction minus actual performance   .37   −.19   Self-prediction minus peer prediction   .30   −.26   Peer overoptimism   Peer-prediction minus actual score   .14   .00   1   Study 1: Self-prediction, peer prediction, and actual Exam 2 score as a function of target score (Panel A) and Exam 1 score (Panel B), controlling for other variables.   2   Study 3: Self-prediction, peer prediction, and actual Round 2 performance as a function of target score adopted (Panel A) and Round 1 score (Panel B), controlling for other variables.   \""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F-Statistics, numeric p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F(1, 40) = 7.90, p < .01',\n",
       " 'F(1, 40) = 8.85, p < .01',\n",
       " 'F(1, 113) = 66.53, p < .0001',\n",
       " 'F(1, 113) = 31.60, p < .0001',\n",
       " 'F(1, 113) = 11.89, p < .001',\n",
       " 'F(1, 114) = 31.26, p < .0001',\n",
       " 'F(1, 114) = 78.84, p < .0001',\n",
       " 'F(1, 114) = 7.49, p < .01',\n",
       " 'F(1, 114) = 4.56, p < .04',\n",
       " 'F(1, 114) = 3.77, p = .05',\n",
       " 'F(1, 114) = 32.83, p < .0001',\n",
       " 'F(1, 114) = 6.50, p < .02']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_stats = re.findall(r'Fs?\\s*\\(\\s*\\d+\\s*\\,\\s*\\d+\\s*\\)\\s*[\\<|\\>|\\=]\\s*\\d*\\.?\\d*\\s*\\,\\s*p\\s*[\\<|\\>|\\=]\\s*\\d*\\.\\d+', \n",
    "                     raw_text)\n",
    "F_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F-Statistics, written non-significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F(1, 114) = 0.02, ns', 'F(1, 114) = 1.54, ns']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_stats_ns = re.findall(r'Fs?\\s*\\(\\s*\\d+\\s*\\,\\s*\\d+\\s*\\)\\s*[\\<|\\>|\\=]\\s*\\d*\\.?\\d*\\s*\\,\\s*n\\.?s\\.?', \n",
    "                        raw_text)\n",
    "F_stats_ns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Scores, numeric p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t(40) = 2.68, p = .01',\n",
       " 't(40) = 2.32, p = .02',\n",
       " 't(102) = 2.66, p < .01',\n",
       " 't(103) = 2.19, p < .04',\n",
       " 't(101) = 2.49, p < .02',\n",
       " 't(101) = 2.05, p < .05',\n",
       " 't(116) = 1.97, p = .05',\n",
       " 't(116) = 3.05, p < .005',\n",
       " 't(116) = 1.61, p < .12']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_scores = re.findall(r't\\s*\\(\\s*\\d*\\s*,?\\s*\\d+\\s*\\)\\s*[\\<|\\>|\\=]\\s*[\\−|\\-]?\\s*\\d*\\.?\\d*\\s*,\\s*p\\s*[\\<|\\>|\\=]\\s*\\d?\\.\\d+',\n",
    "                      raw_text)\n",
    "t_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Scores, numeric p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t(103) = 0.89, ns']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_scores_ns = re.findall(r't\\s*\\(\\s*\\d*\\s*,?\\s*\\d+\\s*\\)\\s*[\\<|\\>|\\=]\\s*[\\−|\\-]?\\s*\\d*\\.?\\d*\\s*,\\s*n\\.?s\\.?',\n",
    "                      raw_text)\n",
    "t_scores_ns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
